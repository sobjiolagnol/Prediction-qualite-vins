# **PrÃ©diction de la QualitÃ© des Vins - README**

![Vin Rouge](https://img.freepik.com/free-photo/red-wine-glass_1409-6220.jpg)

## **ğŸ“Œ AperÃ§u du Projet**
Ce projet vise Ã  prÃ©dire la qualitÃ© des vins Ã  l'aide de techniques d'apprentissage automatique. La qualitÃ© du vin est un facteur essentiel pour les consommateurs et les producteurs, influenÃ§ant sa valeur marchande et son goÃ»t. En utilisant des propriÃ©tÃ©s physico-chimiques des vins, nous construisons des modÃ¨les pour classer leur qualitÃ©, aidant ainsi les producteurs Ã  optimiser leurs processus et les consommateurs Ã  faire de meilleurs choix.

### **ğŸ” Jeu de DonnÃ©es**
Le jeu de donnÃ©es utilisÃ© est le **Wine Quality Dataset** du [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/wine+quality). Il contient des mesures physico-chimiques (aciditÃ©, sucre, alcool, etc.) et des notes de qualitÃ© (0-10) pour des vins rouges et blancs.

### **ğŸ¯ Objectif**
Construire un **modÃ¨le d'apprentissage automatique** capable de prÃ©dire la qualitÃ© du vin en fonction de ses caractÃ©ristiques physico-chimiques.

---

## **ğŸ“Š PrÃ©traitement des DonnÃ©es**
### **1. Gestion des Valeurs Manquantes**
- Aucune valeur manquante dÃ©tectÃ©e (`sns.heatmap(df.isnull())`).

### **2. DÃ©tection et Suppression des Valeurs Aberrantes**
- Utilisation de **l'IQR (Intervalle Interquartile)** et d'une **troncature basÃ©e sur les percentiles** pour Ã©liminer les valeurs extrÃªmes.
- Application d'une **transformation de Box-Cox** pour normaliser les caractÃ©ristiques asymÃ©triques.

### **3. Ã‰quilibrage des DonnÃ©es**
- **SMOTE (Technique de SurÃ©chantillonnage des Minoritaires SynthÃ©tiques)** a Ã©tÃ© utilisÃ© pour Ã©quilibrer le jeu de donnÃ©es, car les donnÃ©es originales prÃ©sentaient des classes dÃ©sÃ©quilibrÃ©es.

### **4. Mise Ã  l'Ã‰chelle des CaractÃ©ristiques**
- **StandardScaler** appliquÃ© pour normaliser les caractÃ©ristiques avant l'entraÃ®nement des modÃ¨les.

---

## **ğŸ¤– ModÃ¨les d'Apprentissage Automatique**
Plusieurs modÃ¨les ont Ã©tÃ© entraÃ®nÃ©s et Ã©valuÃ©s :

| ModÃ¨le | PrÃ©cision | ROC AUC |
|--------|----------|---------|
| **RÃ©gression Logistique** | 0.78 | 0.93 |
| **ForÃªt AlÃ©atoire** | 0.88 | 0.98 |
| **Arbre de DÃ©cision** | 0.82 | 0.95 |
| **Gradient Boosting** | 0.86 | 0.97 |
| **K-Nearest Neighbors (KNN)** | 0.84 | 0.96 |
| **Machine Ã  Vecteurs de Support (SVM)** | 0.80 | 0.94 |

### **ğŸ” Meilleur ModÃ¨le**
- La **ForÃªt AlÃ©atoire** a obtenu la meilleure prÃ©cision (**88%**) et le meilleur ROC AUC (**0.98**).

---

## **ğŸ“ˆ Ã‰valuation des ModÃ¨les**
### **1. Courbes ROC-AUC**
- Ã‰valuation des performances en classification multi-classes.
- La ForÃªt AlÃ©atoire a obtenu le plus haut AUC (0.98), indiquant une excellente sÃ©parabilitÃ© entre les classes.

![Courbes ROC](https://miro.medium.com/v2/resize:fit:1400/1*4PdJ2owkDYQw6Q5fE-5l3A.png)

### **2. Matrices de Confusion**
- La **ForÃªt AlÃ©atoire** a eu le moins de mauvaises classifications.
  
![Matrice de Confusion](https://www.researchgate.net/publication/336402347/figure/fig5/AS:812472659349505@1570719985505/Confusion-matrix-for-Random-Forest-classifier.png)

### **3. Rapports de Classification**
- **PrÃ©cision, Rappel et F1-Score** ont Ã©tÃ© calculÃ©s pour chaque modÃ¨le.
- La **ForÃªt AlÃ©atoire** a obtenu le meilleur F1-score (0.88).

---

## **ğŸš€ Comment ExÃ©cuter le Code**
### **1. Installer les DÃ©pendances**
```bash
pip install numpy pandas scikit-learn matplotlib seaborn xgboost imbalanced-learn ucimlrepo
```

### **2. ExÃ©cuter le Notebook Jupyter**
```bash
jupyter notebook Wine_Quality_Prediction.ipynb
```

### **3. BibliothÃ¨ques ClÃ©s UtilisÃ©es**
- `numpy`, `pandas` (Manipulation des DonnÃ©es)
- `matplotlib`, `seaborn` (Visualisation)
- `scikit-learn` (ModÃ¨les d'Apprentissage Automatique)
- `imbalanced-learn` (SMOTE pour l'Ã‰quilibrage)
- `xgboost` (Gradient Boosting)

---

## **ğŸ“‚ Structure du Projet**
```
PrÃ©diction-QualitÃ©-Vins/
â”‚
â”œâ”€â”€ Wine_Quality_Prediction.ipynb  # Notebook Jupyter Principal
â”œâ”€â”€ README.md                      # Documentation du Projet
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â””â”€â”€ images/                        # Visualisations (optionnel)
```

---

## **ğŸ“ Conclusion**
- La **ForÃªt AlÃ©atoire** est le meilleur modÃ¨le pour prÃ©dire la qualitÃ© du vin (88% de prÃ©cision).
- **Importance des caractÃ©ristiques** : L'alcool, les sulfates et les niveaux d'aciditÃ© Ã©taient les facteurs les plus influents.
- Des amÃ©liorations futures pourraient inclure **l'optimisation des hyperparamÃ¨tres** et l'utilisation de **rÃ©seaux neuronaux**.

---

## **ğŸ“œ Licence**
Ce projet est sous licence **MIT**. Voir [LICENSE](LICENSE) pour plus de dÃ©tails.

---

**ğŸ‘¨â€ğŸ’» Auteur** : [sobjiolagnol]  
**ğŸ“… DerniÃ¨re Mise Ã  Jour** : Juillet 2024  

---
### **ğŸ”— Liens**
- [DÃ©pÃ´t GitHub](https://github.com/lagnolsobjio/prediction-qualite-vins)
- [Jeu de DonnÃ©es UCI Wine Quality](https://archive.ics.uci.edu/ml/datasets/wine+quality)

---
